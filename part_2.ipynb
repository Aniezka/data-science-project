{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PhX_5Makltli"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/hzh/miniconda3/envs/data/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "import string\n",
        "import nltk\n",
        "import zipfile\n",
        "import wikipedia\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import stanza\n",
        "import ast\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ydKYg-rYk7lC"
      },
      "outputs": [],
      "source": [
        "def create_dataset(src, n):\n",
        "    if \"wikipedia.org\" in src:\n",
        "        dataset = data_from_url(src, n)\n",
        "    elif src[-4:] == '.zip' and src[:4] != 'http':\n",
        "      dataset = data_from_archive(n)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid source specified. Please choose 'archive' or 'url'.\")\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "X4jXuHWWlAjg"
      },
      "outputs": [],
      "source": [
        "def data_from_archive(path_to_zip_file, n):\n",
        "    '''\n",
        "    Code to retrieve data from an archive source\n",
        "    '''\n",
        "    dataset = []\n",
        "    count = 0\n",
        "\n",
        "    with zipfile.ZipFile(path_to_zip_file, 'r') as f:\n",
        "      for name in f.namelist():\n",
        "          data = f.read(name)\n",
        "          if count < n:\n",
        "            dataset.append(data)\n",
        "            count += 1\n",
        "          else:\n",
        "            break\n",
        "\n",
        "    return dataset\n",
        "\n",
        "def data_from_url(path_to_url, n):\n",
        "    '''\n",
        "    Code to retrieve data from a URL source\n",
        "    '''  \n",
        "    dataset = []\n",
        "    count = 0\n",
        "\n",
        "    page = wikipedia.page(path_to_url)\n",
        "    content = page.content\n",
        "    dataset.append(content)\n",
        "    \n",
        "    all_links = page.links\n",
        "    for link in all_links:\n",
        "      if count < n-1:\n",
        "        try:\n",
        "          page = wikipedia.page(title=link)\n",
        "          content = page.content\n",
        "          dataset.append(content)\n",
        "          count += 1\n",
        "        except: pass\n",
        "      else:\n",
        "        break\n",
        "    \n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X722NOa0yyYp",
        "outputId": "6e51b303-748b-4d3c-ae18-c8039c053676"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/hzh/miniconda3/envs/data/lib/python3.9/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 389 of the file /Users/hzh/miniconda3/envs/data/lib/python3.9/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  lis = BeautifulSoup(html).find_all('li')\n"
          ]
        }
      ],
      "source": [
        "src = \"https://en.wikipedia.org/wiki/List_of_philosophers_born_in_the_15th_and_16th_centuries\"\n",
        "n = 50\n",
        "\n",
        "dataset = create_dataset(src, n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame(dataset, columns=['texts'])\n",
        "df.to_csv('part2_dataset.csv', index=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# POS tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "      <th>sentences_stanza</th>\n",
              "      <th>sentences_spacy</th>\n",
              "      <th>num_sentences_stanza</th>\n",
              "      <th>num_sentences_spacy</th>\n",
              "      <th>unique_sent_stanza</th>\n",
              "      <th>unique_sent_spacy</th>\n",
              "      <th>tokens_stanza</th>\n",
              "      <th>tokens_spacy</th>\n",
              "      <th>tokens_occurence_stanza</th>\n",
              "      <th>tokens_occurence_spacy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Some notable French Huguenots or people with F...</td>\n",
              "      <td>['Some notable French Huguenots or people with...</td>\n",
              "      <td>['Some notable French Huguenots or people with...</td>\n",
              "      <td>1642</td>\n",
              "      <td>1630</td>\n",
              "      <td>Jean Jacques Favre, pastor.</td>\n",
              "      <td>Antoine Barnave (1761-1783), French revolution...</td>\n",
              "      <td>['notable', 'french', 'huguenot', 'people', 'f...</td>\n",
              "      <td>['notable', 'french', 'huguenot', 'people', 'f...</td>\n",
              "      <td>Counter({'de': 290, 'pastor': 280, 'french': 2...</td>\n",
              "      <td>Counter({'de': 290, 'pastor': 280, 'french': 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Abel Boyer (1667? – 16 November 1729) was a Fr...</td>\n",
              "      <td>['Abel Boyer (1667? – 16 November 1729) was a ...</td>\n",
              "      <td>['Abel Boyer (1667? – 16 November 1729) was a ...</td>\n",
              "      <td>54</td>\n",
              "      <td>51</td>\n",
              "      <td>Glen Buxton said he could listen to Barrett's ...</td>\n",
              "      <td>[The psychiatric evaluation of Jesus.</td>\n",
              "      <td>['abel', 'boyer', 'november', 'french', 'engli...</td>\n",
              "      <td>['abel', 'boyer', 'november', 'french', 'engli...</td>\n",
              "      <td>Counter({'boyer': 27, 'french': 17, 'english':...</td>\n",
              "      <td>Counter({'boyer': 27, 'french': 17, 'english':...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Abolitionism, or the abolitionist movement, is...</td>\n",
              "      <td>['Abolitionism, or the abolitionist movement, ...</td>\n",
              "      <td>['Abolitionism, or the abolitionist movement, ...</td>\n",
              "      <td>332</td>\n",
              "      <td>302</td>\n",
              "      <td>Francis Durand, convert from Roman Catholicism...</td>\n",
              "      <td>Faneuil hall and Faneuil Hall Market: or, Pete...</td>\n",
              "      <td>['abolitionism', 'abolitionist', 'movement', '...</td>\n",
              "      <td>['abolitionism', 'abolitionist', 'movement', '...</td>\n",
              "      <td>Counter({'slavery': 144, 'slave': 118, 'state'...</td>\n",
              "      <td>Counter({'slavery': 171, 'slave': 118, 'state'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In the United States, abolitionism, the moveme...</td>\n",
              "      <td>['In the United States, abolitionism, the move...</td>\n",
              "      <td>['In the United States, abolitionism, the move...</td>\n",
              "      <td>545</td>\n",
              "      <td>518</td>\n",
              "      <td>Renaud (1952-), pop-rock singer, anti-military...</td>\n",
              "      <td>Michael Pertwee (1916-1991), playwright and sc...</td>\n",
              "      <td>['united', 'state', 'abolitionism', 'movement'...</td>\n",
              "      <td>['united', 'state', 'abolitionism', 'movement'...</td>\n",
              "      <td>Counter({'slavery': 151, 'slave': 127, 'abolit...</td>\n",
              "      <td>Counter({'slavery': 207, 'slave': 127, 'abolit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Abraham Bosse (c. 1604 – 14 February 1676) was...</td>\n",
              "      <td>['Abraham Bosse (c.\\u20091604 – 14 February 16...</td>\n",
              "      <td>['Abraham Bosse (c.\\u20091604 – 14 February 16...</td>\n",
              "      <td>65</td>\n",
              "      <td>75</td>\n",
              "      <td>Charles Chauvel (1897–1959), Australian film-m...</td>\n",
              "      <td>Ludwig Devrient (1784–1832), German actor.\\n</td>\n",
              "      <td>['abraham', 'bosse', 'february', 'french', 'ar...</td>\n",
              "      <td>['abraham', 'bosse', 'february', 'french', 'ar...</td>\n",
              "      <td>Counter({'de': 34, 'la': 16, 'bosse': 14, 'le'...</td>\n",
              "      <td>Counter({'de': 34, 'la': 16, 'bosse': 14, 'le'...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               texts   \n",
              "0  Some notable French Huguenots or people with F...  \\\n",
              "1  Abel Boyer (1667? – 16 November 1729) was a Fr...   \n",
              "2  Abolitionism, or the abolitionist movement, is...   \n",
              "3  In the United States, abolitionism, the moveme...   \n",
              "4  Abraham Bosse (c. 1604 – 14 February 1676) was...   \n",
              "\n",
              "                                    sentences_stanza   \n",
              "0  ['Some notable French Huguenots or people with...  \\\n",
              "1  ['Abel Boyer (1667? – 16 November 1729) was a ...   \n",
              "2  ['Abolitionism, or the abolitionist movement, ...   \n",
              "3  ['In the United States, abolitionism, the move...   \n",
              "4  ['Abraham Bosse (c.\\u20091604 – 14 February 16...   \n",
              "\n",
              "                                     sentences_spacy  num_sentences_stanza   \n",
              "0  ['Some notable French Huguenots or people with...                  1642  \\\n",
              "1  ['Abel Boyer (1667? – 16 November 1729) was a ...                    54   \n",
              "2  ['Abolitionism, or the abolitionist movement, ...                   332   \n",
              "3  ['In the United States, abolitionism, the move...                   545   \n",
              "4  ['Abraham Bosse (c.\\u20091604 – 14 February 16...                    65   \n",
              "\n",
              "   num_sentences_spacy                                 unique_sent_stanza   \n",
              "0                 1630                        Jean Jacques Favre, pastor.  \\\n",
              "1                   51  Glen Buxton said he could listen to Barrett's ...   \n",
              "2                  302  Francis Durand, convert from Roman Catholicism...   \n",
              "3                  518  Renaud (1952-), pop-rock singer, anti-military...   \n",
              "4                   75  Charles Chauvel (1897–1959), Australian film-m...   \n",
              "\n",
              "                                   unique_sent_spacy   \n",
              "0  Antoine Barnave (1761-1783), French revolution...  \\\n",
              "1              [The psychiatric evaluation of Jesus.   \n",
              "2  Faneuil hall and Faneuil Hall Market: or, Pete...   \n",
              "3  Michael Pertwee (1916-1991), playwright and sc...   \n",
              "4       Ludwig Devrient (1784–1832), German actor.\\n   \n",
              "\n",
              "                                       tokens_stanza   \n",
              "0  ['notable', 'french', 'huguenot', 'people', 'f...  \\\n",
              "1  ['abel', 'boyer', 'november', 'french', 'engli...   \n",
              "2  ['abolitionism', 'abolitionist', 'movement', '...   \n",
              "3  ['united', 'state', 'abolitionism', 'movement'...   \n",
              "4  ['abraham', 'bosse', 'february', 'french', 'ar...   \n",
              "\n",
              "                                        tokens_spacy   \n",
              "0  ['notable', 'french', 'huguenot', 'people', 'f...  \\\n",
              "1  ['abel', 'boyer', 'november', 'french', 'engli...   \n",
              "2  ['abolitionism', 'abolitionist', 'movement', '...   \n",
              "3  ['united', 'state', 'abolitionism', 'movement'...   \n",
              "4  ['abraham', 'bosse', 'february', 'french', 'ar...   \n",
              "\n",
              "                             tokens_occurence_stanza   \n",
              "0  Counter({'de': 290, 'pastor': 280, 'french': 2...  \\\n",
              "1  Counter({'boyer': 27, 'french': 17, 'english':...   \n",
              "2  Counter({'slavery': 144, 'slave': 118, 'state'...   \n",
              "3  Counter({'slavery': 151, 'slave': 127, 'abolit...   \n",
              "4  Counter({'de': 34, 'la': 16, 'bosse': 14, 'le'...   \n",
              "\n",
              "                              tokens_occurence_spacy  \n",
              "0  Counter({'de': 290, 'pastor': 280, 'french': 2...  \n",
              "1  Counter({'boyer': 27, 'french': 17, 'english':...  \n",
              "2  Counter({'slavery': 171, 'slave': 118, 'state'...  \n",
              "3  Counter({'slavery': 207, 'slave': 127, 'abolit...  \n",
              "4  Counter({'de': 34, 'la': 16, 'bosse': 14, 'le'...  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('tokenization_after_segmentation.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# to be deleted\n",
        "df['tokens_stanza'] = df['tokens_stanza'].apply(ast.literal_eval)\n",
        "df['tokens_spacy'] = df['tokens_spacy'].apply(ast.literal_eval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# to be deleted\n",
        "# creating vocabularies of unique tokens for each library\n",
        "vocab_stanza = set(token for tokens in df['tokens_stanza'] for token in tokens)\n",
        "vocab_spacy = set(token for tokens in df['tokens_spacy'] for token in tokens)\n",
        "\n",
        "# tokens which simalteneously present in both vocabularies\n",
        "SharedTokenInSentences = vocab_stanza.intersection(vocab_spacy)\n",
        "\n",
        "# creating dataframe for storing pos tags\n",
        "df_pos = pd.DataFrame(columns=['token', 'stanza_pos', 'spacy_pos'])\n",
        "df_pos['token'] = list(SharedTokenInSentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-14 14:24:35 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json: 216kB [00:00, 58.6MB/s]                    \n",
            "2023-05-14 14:24:36 INFO: Loading these models for language: en (English):\n",
            "========================\n",
            "| Processor | Package  |\n",
            "------------------------\n",
            "| tokenize  | combined |\n",
            "| pos       | combined |\n",
            "========================\n",
            "\n",
            "2023-05-14 14:24:36 INFO: Using device: cpu\n",
            "2023-05-14 14:24:36 INFO: Loading: tokenize\n",
            "2023-05-14 14:24:36 INFO: Loading: pos\n",
            "2023-05-14 14:24:36 INFO: Done loading processors!\n"
          ]
        }
      ],
      "source": [
        "# pos tagging using stanza\n",
        "nlp_stanza = stanza.Pipeline(lang='en', processors='tokenize,pos')\n",
        "stanza_doc = df_pos['token'].apply(nlp_stanza)\n",
        "df_pos['stanza_pos'] = [token.sentences[0].words[0].upos for token in stanza_doc]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pos tagging using spacy\n",
        "nlp_spacy = spacy.load('en_core_web_sm')\n",
        "df_pos['spacy_pos'] = [t.pos_ for token in df_pos['token'].apply(nlp_spacy) for t in token]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_pos.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Number of tokens in the dataset: {df_pos.shape[0]}\")\n",
        "print(f\"Number of times the token is assigned the same UPOS by both libraries: {df_pos[df_pos['stanza_pos'] == df_pos['spacy_pos']].shape[0]}\")\n",
        "print(f\"Ratio of the times the token is assigned the same UPOS by both libraries: {df_pos[df_pos['stanza_pos'] == df_pos['spacy_pos']].shape[0] / df_pos.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# list of pos tags in each library's results\n",
        "upos_spacy = df_pos['spacy_pos'].unique()\n",
        "upos_stanza = df_pos['stanza_pos'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def frequency_mapping(lib, upos_list):\n",
        "    '''\n",
        "    Map frequency of UPOS tags in one library to the other library\n",
        "    lib: str, 'spacy' or 'stanza'\n",
        "    upos_list: list of UPOS tags in the library\n",
        "    return: dict, mapping of frequencies\n",
        "    '''\n",
        "    if lib == 'spacy':\n",
        "        other_lib = 'stanza'\n",
        "    else:\n",
        "        other_lib = 'spacy'\n",
        "\n",
        "    print(f\"Frequencies of {lib} UPOS tags\")\n",
        "    mapping = {}\n",
        "    for tag in upos_list:\n",
        "        print(f\"\\nFor all tokens labelled {tag} in {lib}:\")\n",
        "\n",
        "        mapping[tag] = {}\n",
        "        sub_df = df_pos[df_pos[f'{lib}_pos'] == tag]\n",
        "        other_lib_tag_list = df_pos[df_pos[f'{lib}_pos'] == tag][f'{other_lib}_pos'].unique()\n",
        "\n",
        "        for other_tag in other_lib_tag_list:\n",
        "            mapping[tag][other_tag] = len(sub_df[sub_df[f'{other_lib}_pos'] == other_tag]) / len(sub_df) * 100\n",
        "        for key, value in mapping[tag].items():\n",
        "            print(f\"{key}: {value:.2f}%\", end=\", \")\n",
        "\n",
        "    return mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mapping_spacy = frequency_mapping('spacy', upos_spacy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mapping_stanza = frequency_mapping('stanza', upos_stanza)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "spacy2stanza = pd.DataFrame(mapping_spacy)\n",
        "stanza2spacy = pd.DataFrame(mapping_stanza)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(spacy2stanza, annot=True, cmap='YlGnBu')\n",
        "plt.title('Spacy to Stanza POS tags')\n",
        "plt.xlabel('Spacy POS')\n",
        "plt.ylabel('Stanza POS')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(stanza2spacy, annot=True, cmap='YlGnBu')\n",
        "plt.title('Stanza to Spacy POS tags')\n",
        "plt.xlabel('Stanza POS')\n",
        "plt.ylabel('Spacy POS')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
